{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in .\\.venv\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in .\\.venv\\lib\\site-packages (from opencv-python) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in .\\.venv\\lib\\site-packages (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q mediapipe\n",
    "%pip install opencv-python\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargar modelo\n",
    "\n",
    "En Unix se puede correr el siguiente comando. En Windows (sin wget) toca descargar el modelo de la URL y poner el archivo en la carpeta `./modelos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -q -O ./modelos/efficientdet_lite0.tflite -q https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/int8/1/efficientdet_lite0.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 480\n",
      "25.0 5665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\dev\\enflujo\\enflujo-emporio-no-benevolente\\.venv\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m milisegundos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m/\u001b[39m fps)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Detectar objetos\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m resultados \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_for_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfotograma_rgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmilisegundos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prediccion \u001b[38;5;129;01min\u001b[39;00m resultados\u001b[38;5;241m.\u001b[39mdetections:\n\u001b[0;32m     41\u001b[0m     cuadro \u001b[38;5;241m=\u001b[39m prediccion\u001b[38;5;241m.\u001b[39mbounding_box\n",
      "File \u001b[1;32mg:\\dev\\enflujo\\enflujo-emporio-no-benevolente\\.venv\\lib\\site-packages\\mediapipe\\tasks\\python\\vision\\object_detector.py:320\u001b[0m, in \u001b[0;36mObjectDetector.detect_for_video\u001b[1;34m(self, image, timestamp_ms, image_processing_options)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs object detection on the provided video frames.\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03mOnly use this method when the ObjectDetector is created with the video\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m  RuntimeError: If object detection failed to run.\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    317\u001b[0m normalized_rect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_to_normalized_rect(\n\u001b[0;32m    318\u001b[0m     image_processing_options, image, roi_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    319\u001b[0m )\n\u001b[1;32m--> 320\u001b[0m output_packets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_video_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_IMAGE_IN_STREAM_NAME\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacket_creator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimestamp_ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_MICRO_SECONDS_PER_MILLISECOND\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_NORM_RECT_STREAM_NAME\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacket_creator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_proto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalized_rect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pb2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestamp_ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_MICRO_SECONDS_PER_MILLISECOND\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_packets[_DETECTIONS_OUT_STREAM_NAME]\u001b[38;5;241m.\u001b[39mis_empty():\n\u001b[0;32m    329\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ObjectDetectorResult([])\n",
      "File \u001b[1;32mg:\\dev\\enflujo\\enflujo-emporio-no-benevolente\\.venv\\lib\\site-packages\\mediapipe\\tasks\\python\\vision\\core\\base_vision_task_api.py:119\u001b[0m, in \u001b[0;36mBaseVisionTaskApi._process_video_data\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_mode \u001b[38;5;241m!=\u001b[39m _RunningMode\u001b[38;5;241m.\u001b[39mVIDEO:\n\u001b[0;32m    115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTask is not initialized with the video mode. Current running mode:\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    117\u001b[0m       \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_mode\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    118\u001b[0m   )\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.tasks.python import BaseOptions\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "opciones = vision.ObjectDetectorOptions(\n",
    "    base_options=BaseOptions(model_asset_path='./modelos/efficientdet_lite0.tflite'),\n",
    "    max_results=5,\n",
    "    score_threshold=0.5,\n",
    "    running_mode=vision.RunningMode.VIDEO)\n",
    "\n",
    "modelo = vision.ObjectDetector.create_from_options(opciones)\n",
    "\n",
    "nombre_archivo = 'GZZ_Leila_03_Carnaval_1 - pan.do_ra AI.webm';\n",
    "\n",
    "video = cv2.VideoCapture('./estaticos/videos/' + nombre_archivo)\n",
    "ancho_video = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "alto_video = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_fotogramas = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print(ancho_video, alto_video)\n",
    "\n",
    "apariciones = []\n",
    "print(fps, total_fotogramas)\n",
    "\n",
    "for i in range(total_fotogramas):\n",
    "    respuesta, fotograma = video.read()\n",
    "    \n",
    "    if respuesta == False:\n",
    "        break\n",
    "    \n",
    "    fotograma_rgb = cv2.cvtColor(fotograma, cv2.COLOR_BGR2RGB)\n",
    "    fotograma_rgb = mp.Image(image_format=mp.ImageFormat.SRGB, data=fotograma_rgb)\n",
    "    milisegundos = int(1000 * i / fps)\n",
    "    \n",
    "    # Detectar objetos\n",
    "    resultados = modelo.detect_for_video(fotograma_rgb, milisegundos)\n",
    "    \n",
    "    for prediccion in resultados.detections:\n",
    "        cuadro = prediccion.bounding_box\n",
    "        x, y, ancho, alto = cuadro.origin_x, cuadro.origin_y, cuadro.width, cuadro.height\n",
    "        categoria = prediccion.categories[0]\n",
    "        confianza = categoria.score * 100\n",
    "        nombre = categoria.category_name\n",
    "        apariciones.append({'categoria': nombre, 'x': x, 'y': y, 'ancho': ancho, 'alto': alto, 'confianza': confianza, 'tiempo': milisegundos})\n",
    "        cv2.rectangle(fotograma, (x, y), (x + ancho, y - 30), (100, 255, 0), -1)\n",
    "        cv2.rectangle(fotograma, (x, y), (x + ancho, y + alto), (100, 255, 0), 2)\n",
    "        cv2.putText(fotograma, f\"{nombre} {confianza:.2f}%\", (x + 5, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "    \n",
    "    cv2.imshow('Video', fotograma)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "datos = json.dumps({'video': nombre_archivo, 'ancho': ancho_video, 'alto': alto_video, 'fps': fps, 'apariciones': apariciones}, separators=(',', \":\"))\n",
    "\n",
    "with open(nombre_archivo + \".json\", \"w\") as outfile:\n",
    "    outfile.write(datos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
